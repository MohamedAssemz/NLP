{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\moham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\moham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\moham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\moham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1156/1156 [==============================] - 3215s 3s/step - loss: 0.7960 - accuracy: 0.9383 - val_loss: 0.4808 - val_accuracy: 0.9402\n",
      "Epoch 2/5\n",
      "1156/1156 [==============================] - 18258s 16s/step - loss: 0.4676 - accuracy: 0.9404 - val_loss: 0.4697 - val_accuracy: 0.9405\n",
      "Epoch 3/5\n",
      "1156/1156 [==============================] - 3084s 3s/step - loss: 0.4547 - accuracy: 0.9406 - val_loss: 0.4648 - val_accuracy: 0.9408\n",
      "Epoch 4/5\n",
      "1156/1156 [==============================] - 3079s 3s/step - loss: 0.4458 - accuracy: 0.9408 - val_loss: 0.4629 - val_accuracy: 0.9408\n",
      "Epoch 5/5\n",
      "1156/1156 [==============================] - 3076s 3s/step - loss: 0.4390 - accuracy: 0.9409 - val_loss: 0.4632 - val_accuracy: 0.9410\n",
      "322/322 [==============================] - 493s 2s/step - loss: 0.4637 - accuracy: 0.9408\n",
      "Test Accuracy: 0.9407767057418823\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "maxlen = 100  # Maximum sequence length\n",
    "embedding_dim = 100  # Dimension of word embeddings\n",
    "lstm_units = 128  # Number of LSTM units (increased for more complexity)\n",
    "batch_size = 32  # Batch size for training\n",
    "epochs = 5  # Number of training epochs\n",
    "\n",
    "# Load the dataset\n",
    "Reg_data = pd.read_csv(\"training_dataset.csv\")\n",
    "\n",
    "X_body = Reg_data['Body_tokens'].apply(lambda x: eval(x)).values\n",
    "X_title = Reg_data['Title_tokens'].apply(lambda x: eval(x)).values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_body, X_title, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Tokenizer and fit on the combined text\n",
    "Reg_tokenizer = Tokenizer()\n",
    "Reg_tokenizer.fit_on_texts(X_body)\n",
    "Reg_tokenizer.fit_on_texts(X_title)\n",
    "\n",
    "# Convert tokens to sequences of integers\n",
    "X_train_seq = Reg_tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = Reg_tokenizer.texts_to_sequences(X_test)\n",
    "y_train_seq = Reg_tokenizer.texts_to_sequences(y_train)\n",
    "y_test_seq = Reg_tokenizer.texts_to_sequences(y_test)\n",
    "\n",
    "# Pad sequences to make them of equal length\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_train_pad = pad_sequences(y_train_seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_test_pad = pad_sequences(y_test_seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "\n",
    "# Train the Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=X_body + X_title, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Initialize the embedding matrix with zeros\n",
    "embedding_matrix = np.zeros((len(Reg_tokenizer.word_index) + 1, embedding_dim))\n",
    "\n",
    "# Fill the embedding matrix with pretrained word vectors\n",
    "for word, i in Reg_tokenizer.word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        embedding_matrix[i] = word2vec_model.wv[word]\n",
    "\n",
    "# Define the LSTM model architecture with pretrained embeddings\n",
    "Reg_model = Sequential()\n",
    "Reg_model.add(Embedding(input_dim=len(Reg_tokenizer.word_index) + 1, output_dim=embedding_dim, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
    "Reg_model.add(LSTM(units=lstm_units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "Reg_model.add(Dense(len(Reg_tokenizer.word_index) + 1, activation='softmax'))  # Predicting word indices\n",
    "\n",
    "# Compile the model\n",
    "Reg_model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "Reg_model.fit(X_train_pad, y_train_pad, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = Reg_model.evaluate(X_test_pad, y_test_pad)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "Predicted Title Probabilities:\n",
      "['play play store store']\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user to enter their input\n",
    "user_input = input(\"Enter the body text: \")\n",
    "\n",
    "user_input_seq = Reg_tokenizer.texts_to_sequences([user_input])\n",
    "user_input_pad = pad_sequences(user_input_seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "\n",
    "# Predict the title based on the user input\n",
    "predicted_title_probs = Reg_model.predict(user_input_pad)\n",
    "\n",
    "print(\"Predicted Title Probabilities:\")\n",
    "\n",
    "# Find the index of the word with the highest probability for each prediction\n",
    "predicted_title_indices = predicted_title_probs.argmax(axis=2)\n",
    "\n",
    "# Convert indices to words\n",
    "predicted_titles = Reg_tokenizer.sequences_to_texts(predicted_title_indices)\n",
    "\n",
    "print(predicted_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8/322 [..............................] - ETA: 1:01:04"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions\n",
    "predictions = Reg_model.predict(X_test_pad)\n",
    "y_pred = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
